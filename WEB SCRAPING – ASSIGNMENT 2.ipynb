{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9d3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import all required libraries\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f43ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APRP Manager / Senior Data Analyst - MeritTrac...</td>\n",
       "      <td>MeritTrac</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Inspira Enterprise India Pvt. Ltd.</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst - PLM Data Migration</td>\n",
       "      <td>CGI</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>People Data Analyst</td>\n",
       "      <td>Western Digital</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Associate Healthcare Research &amp; Data Analyst</td>\n",
       "      <td>Clarivate</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Mobile Premier League (MPL)</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                       Data Analyst   \n",
       "1  APRP Manager / Senior Data Analyst - MeritTrac...   \n",
       "2                                    Sr Data Analyst   \n",
       "3                     Senior Data Management Analyst   \n",
       "4           Senior Data Analyst - PLM Data Migration   \n",
       "5                                People Data Analyst   \n",
       "6       Associate Healthcare Research & Data Analyst   \n",
       "7                                  Lead Data Analyst   \n",
       "8  Contractual Hiring For Top MNC || Business Dat...   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                              Company Experience             Location  \n",
       "0                             Cargill    3-5 Yrs  Bangalore/Bengaluru  \n",
       "1                           MeritTrac   9-14 Yrs  Bangalore/Bengaluru  \n",
       "2  Inspira Enterprise India Pvt. Ltd.    3-4 Yrs  Bangalore/Bengaluru  \n",
       "3                         Wells Fargo    5-7 Yrs  Bangalore/Bengaluru  \n",
       "4                                 CGI    3-6 Yrs  Bangalore/Bengaluru  \n",
       "5                     Western Digital    6-8 Yrs  Bangalore/Bengaluru  \n",
       "6                           Clarivate    3-4 Yrs  Bangalore/Bengaluru  \n",
       "7         Mobile Premier League (MPL)    4-7 Yrs  Bangalore/Bengaluru  \n",
       "8                           TeamLease    5-8 Yrs  Bangalore/Bengaluru  \n",
       "9                           Accenture    6-8 Yrs  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\"\"\"\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up naukri.com website on automated chrome window\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# finding web element for Skill, Designations, Companies search job bar\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# finding web element for search location bar\n",
    "search_locn = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div[1]/input')\n",
    "search_locn.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking on search button\n",
    "search_btn = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Let's extract all web elements having job titles\n",
    "job_titles = []\n",
    "title_tags = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "del job_titles[10:]\n",
    "\n",
    "\n",
    "# Let's extract all web elements having location\n",
    "location = []\n",
    "locn_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "del location[10:]\n",
    "\n",
    "\n",
    "# Let's extract all web elements having company names\n",
    "company_names = []\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "del company_names[10:]\n",
    "\n",
    "\n",
    "# let's extract all web elements having experience\n",
    "experience = []\n",
    "exp_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "del experience[10:]\n",
    "\n",
    "#creating a data frame\n",
    "df = pd.DataFrame({'Job Title':job_titles, 'Company':company_names, 'Experience':experience, 'Location':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba2b8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Citiustech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Program Manager, Analytics</td>\n",
       "      <td>Uber</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Looking For Immediate Joiners</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Altair</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job Title                  Company  \\\n",
       "0                Analystics & Modeling Specialist                Accenture   \n",
       "1                Assistant Manager - Data Science               Citiustech   \n",
       "2                           Senior Data Scientist                    Wipro   \n",
       "3                      Program Manager, Analytics                     Uber   \n",
       "4  Data Scientist - Looking For Immediate Joiners                    Wipro   \n",
       "5                                  Data Scientist                   Altair   \n",
       "6                           Senior Data Scientist  Boston Consulting Group   \n",
       "7                             Data Scientist - II                  Bizongo   \n",
       "8                               Lead ML Scientist        Fractal Analytics   \n",
       "9                           Senior Data Scientist             Baker Hughes   \n",
       "\n",
       "  Experience                                           Location  \n",
       "0    6-8 Yrs  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  \n",
       "1    5-9 Yrs         Hybrid - Bangalore/Bengaluru, Mumbai, Pune  \n",
       "2   6-11 Yrs        Hybrid - Bangalore/Bengaluru, Pune, Chennai  \n",
       "3    3-7 Yrs                                Bangalore/Bengaluru  \n",
       "4   5-10 Yrs  Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...  \n",
       "5    2-7 Yrs  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...  \n",
       "6   5-10 Yrs    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  \n",
       "7    3-6 Yrs     Bangalore/Bengaluru, India, Mumbai (All Areas)  \n",
       "8   6-10 Yrs                        Bangalore/Bengaluru, Mumbai  \n",
       "9    6-8 Yrs                        Bangalore/Bengaluru, Mumbai  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up naukri.com website on automated chrome window\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# finding web element for Skill, Designations, Companies search job bar\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# finding web element for search locn bar\n",
    "search_locn = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div[1]/input')\n",
    "search_locn.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking on search button\n",
    "search_btn = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Let's extract all web elements having job titles\n",
    "job_titles = []\n",
    "title_tags = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "del job_titles[10:]\n",
    "\n",
    "\n",
    "# Let's extract all web elements having location\n",
    "location = []\n",
    "locn_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "del location[10:]\n",
    "\n",
    "\n",
    "# Let's extract all web elements having company names\n",
    "company_names = []\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "del company_names[10:]\n",
    "\n",
    "\n",
    "# let's extract all web elements having experience\n",
    "experience = []\n",
    "exp_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "del experience[10:]\n",
    "\n",
    "#creating a data frame\n",
    "df = pd.DataFrame({'Job Title':job_titles, 'Company':company_names, 'Experience':experience, 'Location':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "644afa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Chennai, Bangal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urgent hiring For Data Scientist (PHD Must Have)</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>Temp. WFH - Noida, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager - Data Science - Banking&amp;Financial Ser...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>Wegarner Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Temp. WFH - Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Meon Technologies</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Razor Group GmbH</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                    DigitalBCG GAMMA Data Scientist   \n",
       "2   Urgent hiring For Data Scientist (PHD Must Have)   \n",
       "3  Manager - Data Science - Banking&Financial Ser...   \n",
       "4                Data Scientist / Sr. Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                             Data scientist- Python   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                              Company Experience  \\\n",
       "0                             HCLTech    4-9 Yrs   \n",
       "1             Boston Consulting Group    2-5 Yrs   \n",
       "2                        NGI Ventures    0-4 Yrs   \n",
       "3                        Black Turtle    4-8 Yrs   \n",
       "4                  Wegarner Solutions    3-8 Yrs   \n",
       "5                torcai digital media    2-7 Yrs   \n",
       "6                   Meon Technologies    2-5 Yrs   \n",
       "7         Alliance Recruitment Agency    3-4 Yrs   \n",
       "8  TeamPlus Staffing Solution Pvt Ltd    3-6 Yrs   \n",
       "9                    Razor Group GmbH    2-3 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Noida, Hyderabad/Secunderabad, Chennai, Bangal...  \n",
       "1                     New Delhi, Bangalore/Bengaluru  \n",
       "2                            Temp. WFH - Noida, Pune  \n",
       "3                   Delhi / NCR, Bangalore/Bengaluru  \n",
       "4                                  Temp. WFH - Noida  \n",
       "5  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...  \n",
       "6                                              Noida  \n",
       "7                                              Noida  \n",
       "8                                   Gurgaon/Gurugram  \n",
       "9                                          New Delhi  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up naukri.com website on automated chrome window\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# finding web element for Skill, Designations, Companies search job bar\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# clicking on search\n",
    "search_btn = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on Delhi / NCR in location filter\n",
    "locn_filter = driver.find_element(By.XPATH,\"//span[@title = 'Delhi / NCR']\")\n",
    "locn_filter.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on 3-6 Lakhs in salary filter\n",
    "sal_filter = driver.find_element(By.XPATH,\"//span[@title = '3-6 Lakhs']\")\n",
    "sal_filter.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Let's extract all web elements having job titles\n",
    "job_titles = []\n",
    "title_tags = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "del job_titles[10:]\n",
    "\n",
    "\n",
    "# Let's extract all web elements having location\n",
    "location = []\n",
    "locn_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "del location[10:]\n",
    "\n",
    "\n",
    "# Let's extract all web elements having company names\n",
    "company_names = []\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "del company_names[10:]\n",
    "\n",
    "\n",
    "# let's extract all web elements having experience\n",
    "experience = []\n",
    "exp_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "del experience[10:]\n",
    "\n",
    "# creating a dataframe\n",
    "df = pd.DataFrame({'Job Title':job_titles, 'Company':company_names, 'Experience':experience, 'Location':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47cc77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Seller's Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Aviator, Clubmaster, Oval, Over-sized, Rectang...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹575</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹519</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹209</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (17)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Riding ...</td>\n",
       "      <td>₹296</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (58)</td>\n",
       "      <td>₹322</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Polarized, UV Protection Cat-eye Sunglasses (55)</td>\n",
       "      <td>₹959</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹230</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                        Description  \\\n",
       "0   Singco India  Aviator, Clubmaster, Oval, Over-sized, Rectang...   \n",
       "1       Fastrack  Gradient, Toughened Glass Lens, UV Protection ...   \n",
       "2       Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3         PIRASO   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "4       Fastrack          UV Protection Rectangular Sunglasses (52)   \n",
       "..           ...                                                ...   \n",
       "95      Fastrack              UV Protection Cat-eye Sunglasses (17)   \n",
       "96        PIRASO  UV Protection, Gradient, Night Vision, Riding ...   \n",
       "97        PIRASO   UV Protection, Gradient Wayfarer Sunglasses (58)   \n",
       "98      Fastrack   Polarized, UV Protection Cat-eye Sunglasses (55)   \n",
       "99     ROYAL SON  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "\n",
       "   Seller's Price Discount  \n",
       "0            ₹499  81% off  \n",
       "1            ₹575  80% off  \n",
       "2            ₹649  35% off  \n",
       "3            ₹519  35% off  \n",
       "4            ₹209  86% off  \n",
       "..            ...      ...  \n",
       "95           ₹379  81% off  \n",
       "96           ₹296  85% off  \n",
       "97           ₹322  78% off  \n",
       "98           ₹959  63% off  \n",
       "99           ₹230  82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up flipkart.com website on automated chrome window\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on CLOSE button of login popup\n",
    "close = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# finding web element for search for products, brands and more bar\n",
    "search_p = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_p.send_keys(\"sunglasses\")\n",
    "\n",
    "# clicking on search button\n",
    "search_btn = driver.find_element(By.XPATH, '//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()\n",
    "time.sleep(7)\n",
    "\n",
    "\n",
    "# initializing required empty list\n",
    "sunglasses = []\n",
    "description = []\n",
    "selling_price = []\n",
    "discount = []\n",
    "\n",
    "while len(sunglasses) < 100:\n",
    "\n",
    "    # Let's extract all web elements having Brand name    \n",
    "    glasses_tags = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in glasses_tags:\n",
    "        sunglasses.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having description    \n",
    "    description_tags = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in description_tags:\n",
    "        description.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having selling price    \n",
    "    selling_price_tags = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in selling_price_tags:\n",
    "        selling_price.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having discount    \n",
    "    discount_tags = driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in discount_tags:\n",
    "        discount.append(i.text)\n",
    "\n",
    "    # clicking on next page button\n",
    "    next_button = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]/span[contains(.,\"Next\")]')\n",
    "    next_button.click()\n",
    "    time.sleep(7)\n",
    "\n",
    "# creating a dataframe\n",
    "df = pd.DataFrame({'Brand':sunglasses[0:100], 'Description':description[0:100], \"Seller's Price\":selling_price[0:100], 'Discount':discount[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec5114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>Worst product delivered by Flipkart\\nAfter 10d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I dreamt about this day from a long time.... G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Great iphone.\\nI am writing this review after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Did an upgrade from 6s plus to iphone 11.\\nAo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>awesome Phone Smooth Touch Too good Sexyy look...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review summary  \\\n",
       "0       5         Simply awesome   \n",
       "1       4        Value-for-money   \n",
       "2       5       Perfect product!   \n",
       "3       5    Best in the market!   \n",
       "4       5     Highly recommended   \n",
       "..    ...                    ...   \n",
       "95      1      Absolute rubbish!   \n",
       "96      5                Awesome   \n",
       "97      5              Just wow!   \n",
       "98      5                 Super!   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   I'm Really happy with the product\\nDelivery wa...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Worst product delivered by Flipkart\\nAfter 10d...  \n",
       "96  I dreamt about this day from a long time.... G...  \n",
       "97  Great iphone.\\nI am writing this review after ...  \n",
       "98  Did an upgrade from 6s plus to iphone 11.\\nAo ...  \n",
       "99  awesome Phone Smooth Touch Too good Sexyy look...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&store=tyy%2F4io&srno=b_1_1&otracker=product_breadCrumbs_APPLE%20Mobiles&fm=organic&iid=ce328902-ec78-47b4-b66a-bd317b10011b.MOBFWQ6BXGJCEYNY.SEARCH&ppt=pp&ppn=pp&ssid=cufkce8yi80000001667569318763\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up apple phone website on automated chrome window\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&store=tyy%2F4io&srno=b_1_1&otracker=product_breadCrumbs_APPLE%20Mobiles&fm=organic&iid=ce328902-ec78-47b4-b66a-bd317b10011b.MOBFWQ6BXGJCEYNY.SEARCH&ppt=pp&ppn=pp&ssid=cufkce8yi80000001667569318763'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on all reviews button to open reviews page\n",
    "close = driver.find_element(By.XPATH, '//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "close.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# initializing required empty lists\n",
    "rating = []\n",
    "review_summary = []\n",
    "review = []\n",
    "\n",
    "while len(rating) <100:\n",
    "    \n",
    "    # Let's extract all web elements for rating\n",
    "    ratings_tags = driver.find_elements(By.XPATH,\"//div[contains(@class, '_3LWZlK ')]\")\n",
    "    for i in ratings_tags:\n",
    "        rating.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements for summary\n",
    "    summary_tags = driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "    for i in summary_tags:\n",
    "        review_summary.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements for review\n",
    "    review_tags = driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for i in review_tags:\n",
    "        review.append(i.text)\n",
    "        \n",
    "    # clicking on next button to open next reviews page\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]/span[contains(.,\"Next\")]')\n",
    "    next_page.click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "# creating a dataframe\n",
    "df = pd.DataFrame({'Rating':rating[:100], 'Review summary':review_summary[:100], \"Full review\":review[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4403b9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Seller's Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WARMFEET</td>\n",
       "      <td>Fancy Sneakers For Men</td>\n",
       "      <td>₹616</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,149</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹395</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,219</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VALLINO Golf Shoes</td>\n",
       "      <td>SD-323 Sneakers For Men</td>\n",
       "      <td>₹3,699</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>ATG-415 Mesh Lace-Ups Sneakers For Men</td>\n",
       "      <td>₹1,549</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>x 1DER Jack V2 Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Outdoor Trendy Lightweight Casual,Canvas Styli...</td>\n",
       "      <td>₹1,529</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Brand  \\\n",
       "0                    Kraasa   \n",
       "1                  WARMFEET   \n",
       "2                  RED TAPE   \n",
       "3                    Labbin   \n",
       "4                    DUCATI   \n",
       "..                      ...   \n",
       "95                    Xtoon   \n",
       "96       VALLINO Golf Shoes   \n",
       "97                     PUMA   \n",
       "98      World Wear Footwear   \n",
       "99  Bond Street By Red Tape   \n",
       "\n",
       "                                          Description Seller's Price Discount  \n",
       "0                                    Sneakers For Men           ₹499  50% off  \n",
       "1                              Fancy Sneakers For Men           ₹616  52% off  \n",
       "2                                    Sneakers For Men         ₹1,149  77% off  \n",
       "3                                    Sneakers For Men           ₹395  60% off  \n",
       "4                                    Sneakers For Men         ₹1,219  65% off  \n",
       "..                                                ...            ...      ...  \n",
       "95                                   Sneakers For Men           ₹499  66% off  \n",
       "96                            SD-323 Sneakers For Men         ₹3,699  47% off  \n",
       "97             ATG-415 Mesh Lace-Ups Sneakers For Men         ₹1,549  69% off  \n",
       "98                    x 1DER Jack V2 Sneakers For Men           ₹249  50% off  \n",
       "99  Outdoor Trendy Lightweight Casual,Canvas Styli...         ₹1,529  70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up flipkart.com website on automated chrome window\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on CLOSE button of login popup\n",
    "close = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# finding web element for search for products, brands and more bar\n",
    "search_p = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_p.send_keys(\"sneakers\")\n",
    "\n",
    "# clicking on search button\n",
    "search_btn = driver.find_element(By.XPATH, '//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# initializing required empty lists\n",
    "sneakers = []\n",
    "description = []\n",
    "selling_price = []\n",
    "discount = []\n",
    "\n",
    "while len(sneakers) < 100:\n",
    "\n",
    "    # Let's extract all web elements having Brand name    \n",
    "    sneakers_tags = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in sneakers_tags:\n",
    "        sneakers.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having description    \n",
    "    description_tags = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in description_tags:\n",
    "        description.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having selling price    \n",
    "    selling_price_tags = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in selling_price_tags:\n",
    "        selling_price.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having discount    \n",
    "    discount_tags = driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in discount_tags:\n",
    "        discount.append(i.text)\n",
    "\n",
    "    # clicking on next page button to scrape data from next page\n",
    "    next_button = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]/span[contains(.,\"Next\")]')\n",
    "    next_button.click()\n",
    "    time.sleep(7)\n",
    "\n",
    "# creating the dataframe of required data\n",
    "df = pd.DataFrame({'Brand':sneakers[0:100], 'Description':description[0:100], \"Seller's Price\":selling_price[0:100], 'Discount':discount[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650dc70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Seller's Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Ultraboost 5.0 DNA Running</td>\n",
       "      <td>Rs 11899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>JORDAN MAX AURA 4 Shoes</td>\n",
       "      <td>Rs 10165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR SonicSE Running Shoes</td>\n",
       "      <td>Rs 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM G.T. Basketball Shoes</td>\n",
       "      <td>Rs 13595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men ChargedEscape 3 BL Running</td>\n",
       "      <td>Rs 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SKO</td>\n",
       "      <td>Men Perforations Leather Loafers</td>\n",
       "      <td>Rs 7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Solid Lug Boots</td>\n",
       "      <td>Rs 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Running Sports Shoes</td>\n",
       "      <td>Rs 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Woman Leather Ankle Boots</td>\n",
       "      <td>Rs 13990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Boots</td>\n",
       "      <td>Rs 13990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                       Description Seller's Price\n",
       "0         ADIDAS    Men Ultraboost 5.0 DNA Running       Rs 11899\n",
       "1           Nike           JORDAN MAX AURA 4 Shoes       Rs 10165\n",
       "2   UNDER ARMOUR    Men HOVR SonicSE Running Shoes        Rs 9999\n",
       "3           Nike    AIR ZOOM G.T. Basketball Shoes       Rs 13595\n",
       "4   UNDER ARMOUR    Men ChargedEscape 3 BL Running        Rs 8999\n",
       "..           ...                               ...            ...\n",
       "95           SKO  Men Perforations Leather Loafers        Rs 7500\n",
       "96          ALDO             Women Solid Lug Boots       Rs 13999\n",
       "97       Bugatti          Men Running Sports Shoes       Rs 13999\n",
       "98          Geox         Woman Leather Ankle Boots       Rs 13990\n",
       "99          Geox                 Women Solid Boots       Rs 13990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description,\n",
    "price of the shoe as shown in the below image.\n",
    "In Case, Inspect click don’t works, Please use ctrl+shift+c to inspect the element.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up myntra.com/shoes website on automated chrome window\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on black in color filter\n",
    "color_filter = driver.find_element(By.XPATH,'//span[@data-colorhex = \"black\"]')\n",
    "color_filter.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on second price filter\n",
    "price_filter = driver.find_element(By.XPATH,\"/html/body/div[2]/div/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# initializing required empty lists\n",
    "shoes = []\n",
    "description = []\n",
    "selling_price = []\n",
    "\n",
    "while len(shoes) < 100:\n",
    "\n",
    "    # Let's extract all web elements having Brand name    \n",
    "    shoes_tags = driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "    for i in shoes_tags:\n",
    "        shoes.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having description    \n",
    "    description_tags = driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "    for i in description_tags:\n",
    "        description.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having selling price    \n",
    "    selling_price_tags = driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "    for i in selling_price_tags:\n",
    "        selling_price.append(\"Rs \" + i.text.split(\"Rs.\")[1].strip())\n",
    "\n",
    "    # clicking on next page button to extract more data\n",
    "    next_button = driver.find_element(By.XPATH, '//li[@class=\"pagination-next\"]')  # to scrap data from next pages as well\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "# creating the dataframe of required data\n",
    "df = pd.DataFrame({'Brand':shoes[0:100], 'Description':description[0:100], \"Seller's Price\":selling_price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44e6db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Selling Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>80,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>93,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>1,04,819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>86,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>25,895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>81,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) HP Workstation Zbook Intel Core i7-4...</td>\n",
       "      <td>null</td>\n",
       "      <td>21,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...  4.3 out of 5 stars   \n",
       "1  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  4.6 out of 5 stars   \n",
       "2  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.1 out of 5 stars   \n",
       "3  Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...  3.9 out of 5 stars   \n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  3.6 out of 5 stars   \n",
       "5  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....  5.0 out of 5 stars   \n",
       "6  (Renewed) HP ProBook 430 G3 6th Gen Intel Core...  3.5 out of 5 stars   \n",
       "7  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...  4.3 out of 5 stars   \n",
       "8  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...  3.8 out of 5 stars   \n",
       "9  (Renewed) HP Workstation Zbook Intel Core i7-4...                null   \n",
       "\n",
       "  Selling Price  \n",
       "0        83,990  \n",
       "1        80,490  \n",
       "2        93,999  \n",
       "3      1,04,819  \n",
       "4        77,990  \n",
       "5        86,490  \n",
       "6        25,895  \n",
       "7        81,490  \n",
       "8        97,990  \n",
       "9        21,990  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "'''\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up amazon.in website on automated chrome window\n",
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# finding web element for search\n",
    "search_p = driver.find_element(By.XPATH,\"//input[@id='twotabsearchtextbox']\")\n",
    "search_p.send_keys(\"Laptop\")\n",
    "\n",
    "# clicking on search button\n",
    "search_btn = driver.find_element(By.XPATH, \"//input[@id='nav-search-submit-button']\")\n",
    "search_btn.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# clicking on Intel Core i7 from CPU type filter\n",
    "cpu_filter = driver.find_element(By.XPATH,\"//li[@aria-label='Intel Core i7']/span/a/span\")\n",
    "cpu_filter.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# initializing required empty lists\n",
    "titles = []\n",
    "ratings = []\n",
    "selling_price = []\n",
    "\n",
    "# Let's extract all web elements having titles    \n",
    "title_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags:\n",
    "    titles.append(i.text)\n",
    "\n",
    "# Let's extract all web elements for searched item using contains\n",
    "items = driver.find_elements(By.XPATH,'//div[contains(@class, \"s-result-item s-asin\")]')\n",
    "\n",
    "for i in items:\n",
    "    \n",
    "    # Let's extract all web elements for rating\n",
    "    ratings_tags = i.find_elements(By.XPATH, './/div[@class=\"a-row a-size-small\"]/span')\n",
    "    \n",
    "    if ratings_tags != []:\n",
    "        rating = ratings_tags[0].get_attribute('aria-label')\n",
    "    else:\n",
    "        rating = 'null'\n",
    "    ratings.append(rating)\n",
    "    \n",
    "    # Let's extract all web elements having selling price    \n",
    "    price_tags = i.find_elements(By.XPATH, './/span[@class=\"a-price-whole\"]')\n",
    "    \n",
    "    if price_tags != []:\n",
    "        price = price_tags[0].text\n",
    "    else:\n",
    "        price = 'null'\n",
    "    selling_price.append(price)\n",
    "\n",
    "# creating the dataframe for the required data\n",
    "df = pd.DataFrame({'Title':titles[0:10], 'Ratings':ratings[0:10], 'Selling Price':selling_price[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc19740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>No matter how plain a woman may be, if truth a...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>Beauty, Beautiful, Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  No matter how plain a woman may be, if truth a...   Eleanor Roosevelt   \n",
       "\n",
       "                                Type of Quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999                  Beauty, Beautiful, Truth  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q9: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1.First get the webpage https://www.azquotes.com/\n",
    "2. Click on Top Quotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quote\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up www.azquotes.com website on automated chrome window\n",
    "url = 'https://www.azquotes.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on TOP QUOTES\n",
    "top_quotes = driver.find_element(By.XPATH,'//*[@id=\"menu\"]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# initializing required empty lists\n",
    "quote =[]\n",
    "author = []\n",
    "type_of_quote = []\n",
    "\n",
    "while len(quote) < 1000:\n",
    "\n",
    "    # Let's extract all web elements having quotes    \n",
    "    quote_tags = driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having author name    \n",
    "    author_tags = driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "\n",
    "    # Let's extract all web elements having type of quote    \n",
    "    type_of_quote_tags = driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "    for i in type_of_quote_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "    # clicking on next button to extract from next page\n",
    "    if len(quote) < 1000:\n",
    "        next_button = driver.find_element(By.XPATH, '//li[@class=\"next\"]/a')  # to scrap data from next pages as well\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "# creating the dataframe\n",
    "df = pd.DataFrame({'Quote':quote, 'Author':author, \"Type of Quote\":type_of_quote})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a1d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964, 16 years 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964, 13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966, 1 year 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966, 13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977, 11 years 59 ...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 , 2 year 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980, 170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984, 4 years 29...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989, 5 years 32...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990, 343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991, 223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996, 4 years 330 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996, 16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997, 324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 , 332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 , 6 years 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   , 10 years 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term of Office  \\\n",
       "0    15 August 1947 to 27 May 1964, 16 years 286 days   \n",
       "1                 27 May 1964 to 9 June 1964, 13 days   \n",
       "2     9 June 1964 to 11 January 1966, 1 year 216 days   \n",
       "3         11 January 1966 to 24 January 1966, 13 days   \n",
       "4   24 January 1966 to 24 March 1977, 11 years 59 ...   \n",
       "5    24 March 1977 to  28 July 1979 , 2 year 126 days   \n",
       "6           28 July 1979 to 14 January 1980, 170 days   \n",
       "7   14 January 1980 to 31 October 1984, 4 years 29...   \n",
       "8   31 October 1984 to 2 December 1989, 5 years 32...   \n",
       "9       2 December 1989 to 10 November 1990, 343 days   \n",
       "10         10 November 1990 to 21 June 1991, 223 days   \n",
       "11      21 June 1991 to 16 May 1996, 4 years 330 days   \n",
       "12                16 May 1996 to 1 June 1996, 16 days   \n",
       "13             1 June 1996 to 21 April 1997, 324 days   \n",
       "14          21 April 1997 to 19 March 1998 , 332 days   \n",
       "15     19 March 1998 to 22 May 2004 , 6 years 64 days   \n",
       "16     22 May 2004 to 26 May 2014   , 10 years 4 days   \n",
       "17                              26 May 2014 - Present   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q10: Write s python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make the DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up www.jagranjosh.com website on automated chrome window\n",
    "url = 'https://www.jagranjosh.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on GK option\n",
    "gk = driver.find_element(By.XPATH,'//*[@id=\"1540978020504\"]/div[1]/header/div[3]/ul/li[9]')\n",
    "gk.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on List of all Prime Ministers of India\n",
    "list_pm = driver.find_element(By.XPATH,'//*[@id=\"popluarGK\"]/ul/li[2]')\n",
    "list_pm.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# initializing required empty lists\n",
    "name = []\n",
    "born_dead = []\n",
    "term_of_office = []\n",
    "remark = []\n",
    "    \n",
    "# Let's extract all web elements having name    \n",
    "name_tags = driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr/td[2]/p')\n",
    "for i in name_tags:\n",
    "    name.append(i.text)\n",
    "    \n",
    "# Let's extract all web elements having born-dead    \n",
    "born_dead_tags = driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr/td[3]/p')\n",
    "for i in born_dead_tags:\n",
    "    born_dead.append(i.text)\n",
    "    \n",
    "# Let's extract all web elements having term of office    \n",
    "term_of_office_tags = driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr/td[4]')\n",
    "for i in term_of_office_tags:\n",
    "    term_of_office.append(i.text.replace(',',\"\").replace('\\n', ', '))\n",
    "    \n",
    "# Let's extract all web elements having remarks    \n",
    "remark_tags = driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr/td[5]/p')\n",
    "for i in remark_tags:\n",
    "    remark.append(i.text)\n",
    "    \n",
    "df = pd.DataFrame({'Name': name, 'Born-Dead': born_dead, 'Term of Office': term_of_office, 'Remarks': remark})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8baf73a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drako GTE</td>\n",
       "      <td>$1.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>$1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>$1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>$1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>$1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>$2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>$2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>$2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>$2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>$3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>$3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>$3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>$3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>$3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>$3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>$4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>$4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>$5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>$5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>$5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>$6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>$7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>$8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>$9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>$12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>$13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>$28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Car                 Price\n",
       "0                         Drako GTE          $1.2 Million\n",
       "1                     De Tomaso P72          $1.3 Million\n",
       "2                 Ferrari LaFerrari          $1.4 Million\n",
       "3                     Pagani Huayra          $1.4 Million\n",
       "4                      McLaren Elva          $1.7 Million\n",
       "5                       Czinger 21C          $1.7 Million\n",
       "6                     Ferrari Monza          $1.7 Million\n",
       "7                Gordon Murray T.33          $1.7 Million\n",
       "8                 Koenigsegg Gemera          $1.7 Million\n",
       "9                       Zenvo TSR-S          $1.7 Million\n",
       "10               Hennessey Venom F5          $1.8 Million\n",
       "11                  Bentley Bacalar          $1.9 Million\n",
       "12    Hispano Suiza Carmen Boulogne          $1.9 Million\n",
       "13           Bentley Mulliner Batur          $2.0 Million\n",
       "14                     Deus Vayanne          $2.0 Million\n",
       "15                      SSC Tuatara         $2.0 Million*\n",
       "16                      Lotus Evija          $2.1 Million\n",
       "17              Aston Martin Vulcan          $2.3 Million\n",
       "18                       Delage D12          $2.3 Million\n",
       "19                McLaren Speedtail          $2.3 Million\n",
       "20                     Rimac Nevera          $2.4 Million\n",
       "21                    Pagani Utopia          $2.5 Million\n",
       "22             Pininfarina Battista          $2.5 Million\n",
       "23                Ferrari FXX K Evo          $2.6 Million\n",
       "24               Gordon Murray T.50          $2.6 Million\n",
       "25             Lamborghini Countach          $2.6 Million\n",
       "26         Mercedes-AMG Project One          $2.7 Million\n",
       "27              Aston Martin Victor          $3.0 Million\n",
       "28      Hennessey Venom F5 Roadster          $3.0 Million\n",
       "29                 Koenigsegg Jesko          $3.0 Million\n",
       "30            Aston Martin Valkyrie          $3.2 Million\n",
       "31        W Motors Lykan Hypersport          $3.4 Million\n",
       "32                    McLaren Solus          $3.5 Million\n",
       "33        Pagani Huayra Roadster BC          $3.5 Million\n",
       "34         Bugatti Chiron Pur Sport          $3.6 Million\n",
       "35                 Lamborghini Sian          $3.6 million\n",
       "36                 Koenigsegg CC850          $3.7 Million\n",
       "37  Bugatti Chiron Super Sport 300+          $3.9 Million\n",
       "38               Lamborghini Veneno          $4.5 Million\n",
       "39                   Bugatti Bolide          $4.7 Million\n",
       "40                  Bugatti Mistral          $5.0 Million\n",
       "41              Pagani Huayra Imola          $5.4 Million\n",
       "42                     Bugatti Divo          $5.8 Million\n",
       "43              SP Automotive Chaos          $6.4 Million\n",
       "44                 Pagani Codalunga          $7.4 Million\n",
       "45         Mercedes-Maybach Exelero          $8.0 Million\n",
       "46               Bugatti Centodieci          $9.0 Million\n",
       "47             Rolls-Royce Sweptail         $12.8 Million\n",
       "48         Bugatti La Voiture Noire         $13.4 Million\n",
       "49           Rolls-Royce Boat Tail*  $28.0 Million (est.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q11: Write s python program to display list of 50 Most expensive cars in the world (i.e. Company name, Model name and Price)\n",
    "from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on left side.\n",
    "3. Then click on 50 most expensive cars in the world.\n",
    "4. Then scrap the mentioned data and make the\n",
    "\"\"\"\n",
    "\n",
    "# Connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Maximize the automated chrome window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening up www.motor1.com website on automated chrome window\n",
    "url = 'https://www.motor1.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# clicking on menu button on left\n",
    "gk = driver.find_element(By.XPATH,'//div[@class = \"m1-hamburger-button\"]')\n",
    "gk.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on lists in the menu opened\n",
    "gk = driver.find_element(By.XPATH,'/html/body/div[3]/div[1]/div[3]/ul/li[4]/a')\n",
    "gk.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on 50 most expensive cars in the world.\n",
    "gk = driver.find_element(By.XPATH,'//*[@id=\"page_index_articles_browse\"]/div[9]/div[1]/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "gk.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# initializing required empty lists\n",
    "car = []\n",
    "price = []\n",
    "\n",
    "# Let's extract all web elements having car names    \n",
    "car_tags = driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in car_tags:\n",
    "    car.append(i.text)\n",
    "del car[50:]\n",
    "\n",
    "# Let's extract all web elements having price    \n",
    "price_tags = driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p/strong')\n",
    "for i in price_tags:\n",
    "    if i.text == \"\":\n",
    "        continue # there was one null value for this tag at 5th position in list so removed it from the list\n",
    "    else:\n",
    "        price.append(i.text.replace(\"Price: \",\"\"))\n",
    "\n",
    "# creating the dataframe\n",
    "df = pd.DataFrame({'Car': car, 'Price': price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7534c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
